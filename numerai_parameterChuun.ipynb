{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "numerai_parameterChuun.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOhkHBPc0y7V",
        "outputId": "60ee10a4-427e-4d85-d162-402f0d7b9084"
      },
      "source": [
        "!pip install numerapi\n",
        "import numerapi\n",
        "NAPI = numerapi.NumerAPI(verbosity=\"info\")\n",
        "import numpy as np\n",
        "import random as rn\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import lightgbm as lgb\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import spearmanr, pearsonr\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import os\n",
        "\n",
        "# Data directory\n",
        "DIR = \"kaggle/working\"\n",
        "#def download_current_data(directory: str):\n",
        "#        \"\"\"\n",
        "#        現在のラウンドのデータをダウンロードします\n",
        "#        ：param directory：データを保存する必要があるディレクトリへのパス\n",
        "#        \"\"\"\n",
        "#        current_round = NAPI.get_current_round()\n",
        "#        if os.path.isdir(f'{directory}/numerai_dataset_{current_round}/'):\n",
        "#            print(f\"You already have the newest data! Current round is: {current_round}\")\n",
        "#        else:\n",
        "#            print(f\"Downloading new data for round: {current_round}!\")\n",
        "#            NAPI.download_current_dataset(dest_path=directory, unzip=True)\n",
        "\n",
        "def load_data(directory: str, reduce_memory: bool=True) -> tuple:\n",
        "        \"\"\"\n",
        "          現在のラウンドのデータを取得する\n",
        "         ：param directory：データを保存する必要があるディレクトリへのパス\n",
        "         ：return：データセットを含むタプル\n",
        "        \"\"\"\n",
        "        print('------------------------------------------Loading the data')\n",
        "        full_path = f'{directory}/numerai_dataset_{NAPI.get_current_round()}/'\n",
        "        train_path = full_path + 'numerai_training_data.csv'\n",
        "        test_path = full_path + 'numerai_tournament_data.csv'\n",
        "        train = pd.read_csv(train_path)\n",
        "        test = pd.read_csv(test_path)\n",
        "        print('------------------------------------------End of loading the data')\n",
        "        # Reduce all features to 32-bit floats\n",
        "        if reduce_memory:\n",
        "            num_features = [f for f in train.columns if f.startswith(\"feature\")]\n",
        "            train[num_features] = train[num_features].astype(np.float32)\n",
        "            test[num_features] = test[num_features].astype(np.float32)\n",
        "        # numerai_tournament_dataにはラベルが与えられているValidationデータと与えられてないテストデータがある\n",
        "        # validation split\n",
        "        # valid.loc[valid[\"era\"] > 180, \"valid2\"] = True # むずいやつ\n",
        "        # valid.loc[valid[\"era\"] <= 180, \"valid2\"] = False # 簡単なやつ\n",
        "        val = test[test['data_type'] == 'validation']\n",
        "        test = test[test['data_type'] != 'validation']\n",
        "        print('------------------------------------------END')\n",
        "        return train, val, test\n",
        "    \n",
        "    \n",
        "# Download, unzip and load data\n",
        "# download_current_data(DIR)\n",
        "# train, val, test = load_data(DIR, reduce_memory=True)\n",
        "\n",
        "\n",
        "def sharpe_ratio(corrs: pd.Series) -> np.float32:\n",
        "        \"\"\"\n",
        "        グループ化された時代ごとのデータを使用して、ヌメライのシャープレシオを計算します\n",
        "\n",
        "         ：param corrs：各時代のスピアマンの相関係数を含むパンダシリーズ\n",
        "         ：return：予測のシャープレシオを示すフロート。\n",
        "        \"\"\"\n",
        "        return corrs.mean() / corrs.std()\n",
        "\n",
        "\n",
        "def evaluate(df: pd.DataFrame) -> tuple:\n",
        "        \"\"\"\n",
        "        ヌメライに関連する指標を評価して表示する\n",
        "\n",
        "         ：param df：「era」、「target_kazutsugi」の列と予測用の列を含むPandasDataFrame\n",
        "         ：param pred_col：予測が保存される列\n",
        "         ：return：メトリックを含むfloatのタプル\n",
        "        \"\"\"\n",
        "        def _score(sub_df: pd.DataFrame) -> np.float32:\n",
        "            \"\"\"Calculates Spearman correlation\"\"\"\n",
        "            return spearmanr(sub_df[\"target\"], sub_df[\"prediction\"])[0]\n",
        "\n",
        "        # Calculate metrics\n",
        "        corrs = df.groupby(\"era\").apply(_score)\n",
        "        print(corrs)\n",
        "        payout_raw = (corrs / 0.2).clip(-1, 1)\n",
        "        spearman = round(corrs.mean(), 4)\n",
        "\n",
        "        payout = round(payout_raw.mean(), 4)\n",
        "        numerai_sharpe = round(sharpe_ratio(corrs), 4)\n",
        "        mae = mean_absolute_error(df[\"target\"], df[\"prediction\"]).round(4)\n",
        "\n",
        "        # Display metrics\n",
        "        print(f\"Spearman Correlation: {spearman}\")\n",
        "        print(f\"Average Payout: {payout}\")\n",
        "        print(f\"Sharpe Ratio: {numerai_sharpe}\")\n",
        "        print(f\"Mean Absolute Error (MAE): {mae}\")\n",
        "        return spearman, payout, numerai_sharpe, mae\n",
        "\n",
        "def neutralize(series,by, proportion):\n",
        "    \n",
        "    scores = series.values.reshape(-1, 1)\n",
        "    exposures = by.values.reshape(-1, 1)\n",
        "    exposures = np.hstack((exposures, np.array([np.mean(series)] * len(exposures)).reshape(-1, 1)))\n",
        "    correction = proportion * (exposures.dot(np.linalg.lstsq(exposures, scores)[0]))\n",
        "    corrected_scores = scores - correction\n",
        "    neutralized = pd.Series(corrected_scores.ravel(), index=series.index)\n",
        "    \n",
        "    return neutralized\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numerapi in /Users/hiro/.pyenv/versions/3.9.1/lib/python3.9/site-packages (2.4.0)\r\n",
            "Requirement already satisfied: requests in /Users/hiro/.pyenv/versions/3.9.1/lib/python3.9/site-packages (from numerapi) (2.25.1)\r\n",
            "Requirement already satisfied: click>=7.0 in /Users/hiro/.pyenv/versions/3.9.1/lib/python3.9/site-packages (from numerapi) (7.1.2)\r\n",
            "Requirement already satisfied: pytz in /Users/hiro/.pyenv/versions/3.9.1/lib/python3.9/site-packages (from numerapi) (2020.5)\r\n",
            "Requirement already satisfied: tqdm>=4.29.1 in /Users/hiro/.pyenv/versions/3.9.1/lib/python3.9/site-packages (from numerapi) (4.56.0)\r\n",
            "Requirement already satisfied: python-dateutil in /Users/hiro/.pyenv/versions/3.9.1/lib/python3.9/site-packages (from numerapi) (2.8.1)\r\n",
            "Requirement already satisfied: six>=1.5 in /Users/hiro/.pyenv/versions/3.9.1/lib/python3.9/site-packages (from python-dateutil->numerapi) (1.15.0)\r\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/hiro/.pyenv/versions/3.9.1/lib/python3.9/site-packages (from requests->numerapi) (4.0.0)\r\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/hiro/.pyenv/versions/3.9.1/lib/python3.9/site-packages (from requests->numerapi) (2020.12.5)\r\n",
            "Requirement already satisfied: idna<3,>=2.5 in /Users/hiro/.pyenv/versions/3.9.1/lib/python3.9/site-packages (from requests->numerapi) (2.10)\r\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/hiro/.pyenv/versions/3.9.1/lib/python3.9/site-packages (from requests->numerapi) (1.26.2)\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OweICdgi0y7a",
        "outputId": "d1772202-03fb-400d-f6de-88f2025523bb"
      },
      "source": [
        "train, val, test = load_data(DIR, reduce_memory=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------------------------------------Loading the data\n",
            "------------------------------------------End of loading the data\n",
            "------------------------------------------END\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oSDVLoJ0y7a"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbg4tqLd0y7a"
      },
      "source": [
        "def get_group_stats(df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        各グループの統計モーメントを計算して、特徴を作成します。\n",
        "\n",
        "         ：param df：すべての機能を含むPandas DataFrame\n",
        "        \"\"\"\n",
        "        for group in [\"intelligence\", \"wisdom\", \"charisma\", \"dexterity\", \"strength\", \"constitution\"]:\n",
        "            cols = [col for col in df.columns if group in col]\n",
        "            df[f\"feature_{group}_mean\"] = df[cols].mean(axis=1)\n",
        "            df[f\"feature_{group}_std\"] = df[cols].std(axis=1)\n",
        "            df[f\"feature_{group}_skew\"] = df[cols].skew(axis=1)\n",
        "        return df\n",
        "\n",
        "    # Add group statistics features\n",
        "\n",
        "\n",
        "train = get_group_stats(train)\n",
        "val = get_group_stats(val)\n",
        "test = get_group_stats(test)\n",
        "print('------------------------------------------END')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-svbNHI0y7b"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "interactions = preprocessing.StandardScaler()\n",
        "#ft_corr_list=['feature_dexterity7', 'feature_charisma18', 'feature_charisma63', 'feature_dexterity14']#ft_corr_listは交互作用特徴量を作りたいものを入れる。\n",
        "ft_corr_list=['feature_constitution96', 'feature_wisdom32', 'feature_constitution32', 'feature_strength14', 'feature_intelligence3', 'feature_dexterity7']\n",
        "interactions.fit(train[ft_corr_list], train[\"target\"])\n",
        "X_train_interact = pd.DataFrame(interactions.transform(train[ft_corr_list]))\n",
        "X_best_val_inter =pd.DataFrame(interactions.transform(val[ft_corr_list]))\n",
        "X_best_test_inter =pd.DataFrame(interactions.transform(test[ft_corr_list]))\n",
        "\n",
        "train=train.reset_index().drop(columns='index')\n",
        "train=pd.concat([train,X_train_interact],axis=1)\n",
        "\n",
        "val=val.reset_index().drop(columns='index')\n",
        "val=pd.concat([val,X_best_val_inter],axis=1)\n",
        "\n",
        "test=test.reset_index().drop(columns='index')\n",
        "test=pd.concat([test,X_best_test_inter],axis=1)\n",
        "print('------------------------------------------END')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lzbAtgZ0y7b"
      },
      "source": [
        "feature_list=train.columns.drop('id').drop('era').drop('data_type').drop('target')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_od54Rh0y7b"
      },
      "source": [
        "feature_list=['feature_intelligence_mean', 'feature_intelligence_std', 'feature_intelligence_skew', 'feature_wisdom_mean', 'feature_wisdom_std', 'feature_wisdom_skew', \n",
        "              'feature_charisma_mean', 'feature_charisma_std', 'feature_charisma_skew', 'feature_dexterity_mean', 'feature_dexterity_std', 'feature_dexterity_skew', \n",
        "              'feature_strength_mean', 'feature_strength_std', 'feature_strength_skew','feature_constitution_mean', 'feature_constitution_std', 'feature_constitution_skew',\n",
        "             'feature_constitution96','feature_wisdom32','feature_constitution32','feature_strength14','feature_intelligence3','feature_dexterity7','0','1','2','3','4','5']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSuUG9ob0y7b"
      },
      "source": [
        "feature_list=['feature_constitution96','feature_wisdom32','feature_constitution32','feature_strength14','feature_intelligence3','feature_dexterity7']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rGnvfhE0y7b"
      },
      "source": [
        "print(feature_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfQ5hfak0y7c"
      },
      "source": [
        "#\n",
        "\n",
        "#\n",
        "dtrain = lgb.Dataset(train[feature_list].fillna(0), label=train[\"target\"])\n",
        "dvalid = lgb.Dataset(val[feature_list].fillna(0), label=val[\"target\"])\n",
        "print('------------------------------------------END')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eatQEKeI0y7c"
      },
      "source": [
        "best_config ={\"objective\": \"regression\", \"metric\": \"l2\", \"verbosity\": 10, \"feature_pre_filter\": False,\n",
        "              \"lambda_l1\": 0.0163973329416619, \"lambda_l2\": 6.592372824860872e-08, \"num_leaves\": 31,\n",
        "              \"feature_fraction\": 1.0, \"bagging_fraction\": 1.0, \"bagging_freq\": 0, \"min_child_samples\": 20,'num_iterations': 1000,\n",
        "              \"learning_rate\":0.01,\"n_estimators\":1750,\"max_depth\":4, \"random_state\": 0} "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUyc82jA0y7c"
      },
      "source": [
        "best_config ={'objective': 'regression', 'metric': 'l2', 'verbosity': 10, 'feature_pre_filter': False, \n",
        "              'lambda_l1': 0.0163973329416619, 'lambda_l2': 6.592372824860872e-08,\n",
        "              'num_leaves': 31,\n",
        "              'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'min_child_samples': 20, 'num_iterations': 1000, 'early_stopping_round': 100}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvmwJvki0y7c"
      },
      "source": [
        "best_config ={\"objective\":\"regression\", \"num_leaves\":31,\"learning_rate\":0.01,\"n_estimators\":1750,\"max_depth\":4,\"metric\":\"mse\",\"verbosity\": 10, \"random_state\": 0} "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcS0OXWU0y7c"
      },
      "source": [
        "best_config ={\"objective\":\"regression\", \"num_leaves\":31,\"learning_rate\":0.01,\"n_estimators\":3389,\"max_depth\":2,\"metric\":\"mse\",\"verbosity\": 10, \"random_state\": 0} "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McXvuBsN0y7c"
      },
      "source": [
        "best_config ={\"objective\":\"regression\", \"learning_rate\":0.01,\"max_depth\":5,'boosting_type': 'gbdt','feature_fraction': 0.1,'seed': 42} "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STi9-Jtd0y7c"
      },
      "source": [
        "# 通常のLGB\n",
        "#best_config ={\"objective\":\"regression\", \"num_leaves\":31,\"learning_rate\":0.01,\"n_estimators\":2000,\"max_depth\":5,\"metric\":\"mse\",\"verbosity\": 10, \"random_state\": 0} \n",
        "#\n",
        "\n",
        "model = lgb.train(best_config, dtrain)\n",
        "train.loc[:, \"prediction\"] = model.predict(train[feature_list])\n",
        "val.loc[:,\"prediction\"]=val[\"target\"]\n",
        "val.loc[:,\"prediction\"] = model.predict(val[feature_list])\n",
        "print('------------------------------------------END')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkXIF1v-0y7d",
        "outputId": "2056a96e-ff8b-4e47-aeca-bd0476baa64e"
      },
      "source": [
        "model = lgb.LGBMRegressor(**best_config)\n",
        "model.fit(train[feature_list],train[\"target\"])\n",
        "train.loc[:, \"prediction\"] = model.predict(train[feature_list])\n",
        "val.loc[:,\"prediction\"]=val[\"target\"]\n",
        "val.loc[:,\"prediction\"] = model.predict(val[feature_list])\n",
        "print('------------------------------------------END')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "------------------------------------------END\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cp7bh48_0y7d"
      },
      "source": [
        "# ハイパーパラメータ最適化\n",
        "import optuna\n",
        "def opt(trialO):\n",
        "    n_estimators = trialO.suggest_int('n_estimators', 500, 4000)\n",
        "    max_depth = trialO.suggest_int('max_depth', 1, 20)\n",
        "    #min_child_weight = trialO.suggest_int('min_child_weight', 1, 20)\n",
        "    #subsample = trialO.suggest_discrete_uniform('subsample', 0.5, 0.9, 0.1)\n",
        "    #colsample_bytree = trialO.suggest_discrete_uniform('colsample_bytree', 0.5, 0.9, 0.1)\n",
        "    model_opt = lgb.LGBMRegressor(\n",
        "        #random_state=42,\n",
        "        random_state=0,\n",
        "        num_boost_round=1000,\n",
        "        n_estimators = n_estimators,\n",
        "        max_depth = max_depth,\n",
        "        #min_child_weight = min_child_weight,\n",
        "        #subsample = subsample,\n",
        "        #colsample_bytree = colsample_bytree,\n",
        "        learning_rate=0.01,\n",
        "        metric=\"mse\",\n",
        "        verbosity=10\n",
        "        \n",
        "    )\n",
        "    model_opt.fit(train[feature_list], train[\"target\"])\n",
        "    opt_pred = model_opt.predict(val[feature_list])\n",
        "    return (1.0 - (model_opt.score(val[feature_list], val[\"target\"])))\n",
        "\n",
        "model_opt=lgb.LGBMRegressor()\n",
        "study = optuna.create_study()\n",
        "study.optimize(opt, n_trials=100)\n",
        "print(study.best_params)\n",
        "print(1-study.best_value)\n",
        "print('------------------------------------------END')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iG7oXC8t0y7d"
      },
      "source": [
        "# ハイパーパラメータ最適化\n",
        "import optuna.integration.lightgbm as lgb_optuna\n",
        "\n",
        "param = {\n",
        "        'objective': 'regression'\n",
        "        'metric': 'mse',\n",
        "        'verbosity': 10,\n",
        "    }\n",
        "\n",
        "best = lgb_optuna.train(param, \n",
        "                 dtrain,\n",
        "                 valid_sets=dvalid,\n",
        "                 early_stopping_rounds=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V60ycoA50y7d"
      },
      "source": [
        "print(best.params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2ObqnxZ0y7e"
      },
      "source": [
        "print(best.best_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLVQPTCn0y7e",
        "outputId": "aad6d4ec-0f04-48c1-bc0c-c71f30cdc049"
      },
      "source": [
        "feature_spearman_val = [spearmanr(val[\"prediction\"], val[f])[0] for f in feature_list]\n",
        "feature_exposure_val = np.std(feature_spearman_val).round(4)\n",
        "spearman, payout, numerai_sharpe, mae = evaluate(val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "era\n",
            "era121    0.025718\n",
            "era122    0.030021\n",
            "era123    0.054352\n",
            "era124    0.067290\n",
            "era125    0.051013\n",
            "era126    0.025927\n",
            "era127   -0.020346\n",
            "era128    0.064889\n",
            "era129    0.001306\n",
            "era130    0.043659\n",
            "era131    0.022118\n",
            "era132    0.067764\n",
            "era197    0.024853\n",
            "era198   -0.004059\n",
            "era199   -0.042764\n",
            "era200    0.006934\n",
            "era201   -0.021094\n",
            "era202    0.036511\n",
            "era203    0.013599\n",
            "era204    0.005637\n",
            "era205   -0.010685\n",
            "era206   -0.005159\n",
            "era207    0.066488\n",
            "era208    0.036663\n",
            "era209    0.051599\n",
            "era210   -0.010853\n",
            "era211   -0.050050\n",
            "era212    0.010810\n",
            "dtype: float64\n",
            "Spearman Correlation: 0.0194\n",
            "Average Payout: 0.0968\n",
            "Sharpe Ratio: 0.5883\n",
            "Mean Absolute Error (MAE): 0.1507\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQz1PAEm0y7e"
      },
      "source": [
        "train=0#メモリ削減\n",
        "import time \n",
        "time.sleep(5)\n",
        "val[['id', \"prediction\"]].to_csv(\"submission_val.csv\", index=False)\n",
        "val=0#メモリ削減\n",
        "time.sleep(5)\n",
        "test.loc[:, \"prediction\"] =0\n",
        "test.loc[:, \"prediction\"] = model.predict(test[feature_list])\n",
        "test[['id', \"prediction\"]].to_csv(\"submission_test.csv\", index=False)\n",
        "test=0#メモリ削減\n",
        "time.sleep(5)\n",
        "print('------------------------------------------END')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwautPLL0y7e"
      },
      "source": [
        "directory = \"kaggle/working\"\n",
        "full_path = f'{directory}/numerai_dataset_{NAPI.get_current_round()}/'\n",
        "test_path = full_path + 'numerai_tournament_data.csv'\n",
        "tournament_data = pd.read_csv(test_path)\n",
        "tournament_data_id=tournament_data['id']\n",
        "tournament_data_id2=tournament_data['feature_dexterity7']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ekw64uNr0y7e"
      },
      "source": [
        "tournament_data_id2.head(15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXOorFNq0y7e"
      },
      "source": [
        "tournament_data_id=pd.concat([tournament_data_id,tournament_data_id2],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJphYO_J0y7e"
      },
      "source": [
        "tournament_data_id.head(15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B32Ha4l60y7e"
      },
      "source": [
        "val=pd.read_csv(\"submission_val.csv\")\n",
        "test=pd.read_csv(\"submission_test.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPnOyw8R0y7f"
      },
      "source": [
        "test_val_concat=pd.concat([val[['id', \"prediction\"]],test[['id', \"prediction\"]]],axis=0).set_index('id')\n",
        "tournament_data_id=tournament_data_id.set_index('id')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyrVw5UJ0y7f"
      },
      "source": [
        "tournament_data_id.head(15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6VVU-_A0y7f"
      },
      "source": [
        "conc_submit=pd.concat([tournament_data_id,test_val_concat],axis=1).drop(columns='feature_dexterity7').reset_index()\n",
        "conc_submit=conc_submit.rename(columns={'index': 'id'})\n",
        "conc_submit.to_csv(\"submission_file\"+\".csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zy_tAufz0y7f"
      },
      "source": [
        "by=pd.read_csv('kaggle/working/numerai_dataset_'+str(NAPI.get_current_round())+'/example_predictions.csv')\n",
        "neut=pd.read_csv(\"submission_file.csv\")\n",
        "neut=pd.DataFrame({'prediction':neutralize(neut['prediction'],by['prediction'], 0.3)})#ここを弄ると、Neutralizeの量を変化させることができる。\n",
        "conc=pd.concat([by.drop(columns=\"prediction\"),neut],axis=1)\n",
        "conc.to_csv(\"neutralized_submission_file\"+ now.strftime('%Y%m%d_%H%M%S') + \".csv\", index=False)#提出ファイル\n",
        "\n",
        "print('------------------------------------------END')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyTbwMIuQg4C"
      },
      "source": [
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEfqpxcEWDdK"
      },
      "source": [
        "# Get your API keys and model_id from https://numer.ai/submit\n",
        "#public_id = \"\"\n",
        "#secret_key = \"\"\n",
        "#model_id = \"\"\n",
        "#napi = numerapi.NumerAPI(public_id=public_id, secret_key=secret_key)\n",
        "#submission_id = napi.upload_predictions(\"neutralized_submission_file.csv\", model_id=model_id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teXIZ3DQT2Pv"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('neutralized_submission_file.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2Lf95xi0y7f"
      },
      "source": [
        "ls kaggle/working/numerai_dataset_249/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHNVQx2C0y7f"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "interactions = preprocessing.StandardScaler()\n",
        "ft_corr_list=['feature_dexterity7', 'feature_charisma18', 'feature_charisma63', 'feature_dexterity14']#ft_corr_listは交互作用特徴量を作りたいものを入れる。\n",
        "interactions.fit(train[ft_corr_list], train[\"target\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ykFx5Dt0y7f"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kcyeyvA0y7g"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}